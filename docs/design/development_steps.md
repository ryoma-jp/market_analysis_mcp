# 技術動向調査エージェント: 開発手順（推奨プロセス）

## 前提（デフォルト案）
- 実装形態: **MCPサーバー（stdio）**として実装し、GitHub Copilot のカスタムエージェントからツールとして呼び出す
- 理由: 会話 → ツール呼び出し → 成果物保存（`sources/` / `reports/`）までを一連で自動化しやすく、再現性（URLログ）も担保しやすい
- 実装言語/配置: Python。実行環境は `env/`、ソースコードは `src/` に配置する
- 対象コンテンツ（MVP）: まずは **HTMLのみ**（PDF/画像/動画字幕は次フェーズ）
- 根拠の現文（抜粋）: 1つの抜粋は **最大500文字**、URL + 位置情報（見出し名/段落/タイムスタンプ等）を可能な範囲で付与
- 収集ポリシー: 一次情報（公式/企業）優先。必要最小限の短い抜粋に留める（長文転載は避ける）
- 保存/再現性: `sources/` に収集ログ、`reports/` にMarkdownレポートを保存（命名規則は4.2で固定）
- git管理: 生成物（`sources/` / `reports/`）は **デフォルトでgit管理外（.gitignore）** とし、必要なレポートのみコミットできる運用を推奨
- 運用安全性: User-Agent明示、レート制限、タイムアウト/リトライ、ドメインallowlist（設定ファイル化）
- Docker（`env/`）: `python:3.11-slim` もしくは `python:3.12-slim` をベースにし、locale/TZを設定。プロキシ/CA/タイムアウト等は環境変数で注入できる設計にする

## 0. まず決めること（最重要）
- **アウトプットの型**: 速報/標準/深掘りのどれを主にするか
- **一次情報優先**: 公式/企業発表を最優先にする
- **守るルール**: 長文転載をしない、出典URLを必ず付ける、噂は噂として扱う

---

## 1. MVPを最小化する（1〜2日で作る）
### MVP要件
- 入力: `event`（例: CES 2026）, `date_range`, `topics`（任意）
- 出力:
  - エグゼクティブサマリ
  - トレンドTop5
  - 根拠の現文（短い抜粋） + 参照URL（各トレンド最低2本）

### 失敗しやすい点（先に潰す）
- 収集ソースが増えすぎて破綻 → 最初は「公式 + 主要企業 + 主要メディア2つ」に限定
- まとめが抽象的 → “何が新しいか/昨年比”の軸を必須にする

---

## 2. 実装方式の選定（おすすめ順）
### A. Copilot + ツール連携（MCPサーバー等）: 推奨
**狙い**: エージェントに「Web取得/抽出/キャッシュ/ログ保存」をツールとして持たせる。
- 長所: 再現性（URLログ）、自動化（毎日回す）、保守しやすい
- 短所: 実装が必要（サーバー/ツール定義）

作るツール例:
- `search_web(query, time_range)`
- `fetch_url(url)`（HTML取得）
- `extract_main_text(html)`（本文抽出）
- `extract_evidence_quotes(text, claims)`（結論/見解に対応する短い根拠抜粋を抽出）
- `summarize(text, focus)`
- `save_report(markdown)` / `save_sources(json)`

### B. Copilot カスタム指示（プロンプト運用）: 最短
**狙い**: 手動でURLを渡し、定型出力でまとめる。
- 長所: 実装ほぼ不要
- 短所: 収集が人力、漏れ/偏りが出やすい、再現性が弱い

### C. 外部のクローラ/ETL + Copilot（分離）: 大規模向け
**狙い**: 収集と要約を分ける（収集は定期ジョブ、要約はCopilot）。
- 長所: スケールしやすい
- 短所: 構成が複雑

---

## 3. 設計（先にドキュメント化すると速い）
推奨は、先に設計を固めてから実装。
- 収集対象のリスト（公式/企業/メディア）
- タクソノミ（カテゴリ付け）
- 信頼度ルール（一次/二次/ソーシャル）
- 出力テンプレ（見出し固定）

既存のひな形: [agent_spec.md](./agent_spec.md)

---

## 4. 実装ステップ（A: ツール連携ルートの場合）
### 4.1 最初に作るべきツール
1) `fetch_url`（取得）
2) `extract_main_text`（本文抽出）
3) `save_sources`（URL/日時/タイトルのログ）
4) `save_report`（Markdown出力）

※ 根拠の現文（短い抜粋）を出したい場合は、MVPの次の一手として `extract_evidence_quotes` 相当を追加すると品質が安定します。

※ `search_web` は精度が荒れやすいので、最初は「固定ソースのRSS/サイトマップ」でも可。

### 4.2 生成物（リポジトリ内の置き場所例）
- `reports/YYYY/ces-2026-day1.md`
- `sources/YYYY/ces-2026-day1.json`

### 4.3 ツール境界とI/O（MVP推奨）
MVP段階の推奨は「HTMLのみ」を前提に、以下の境界を固定しておくこと。

#### `fetch_url`
- 入力: `url`
- 出力（最低限）:
  - `final_url`（リダイレクト後）
  - `status_code`
  - `fetched_at`（ISO 8601）
  - `content_type`
  - `html`（テキスト）
- 振る舞い: タイムアウト、リトライ、User-Agent明示、レート制限、robots/利用規約への配慮

#### `extract_main_text`
- 入力: `html`, `base_url`（相対リンク解決用）
- 出力（最低限）:
  - `title`
  - `main_text`
  - `published_date`（推定可、取れなければnull）
  - `publisher`（hostやメタタグから推定可）
- 目的: 「タイトル＋本文」を確実に取る（後段の抜粋生成の精度を上げる）

#### `save_sources`
- 入力: “発信”単位のメタデータ配列
  - 推奨最小メタ: `url`, `final_url`, `fetched_at`, `title`, `publisher/host`, `published_date(推定可)`, `category(任意)`, `confidence(暫定)`
- 出力: 保存先パス、件数

#### `save_report`
- 入力: Markdown（固定テンプレ）
- 出力: 保存先パス
- 目的: 見出しが固定されることで差分比較しやすく、日次運用が安定する

#### 根拠の現文（最大500文字）
- MVPから必須にする場合は、本文から該当箇所を短く抜粋し **最大500文字を強制** する
- 抽出ロジックは改善可能なように分離（`extract_evidence_quotes` 相当）し、将来の精度向上で出力を壊さない

### 4.4 設定（運用事故防止のための推奨）
- ドメインallowlist（取得許可ドメイン）を設定ファイルで持つ（最初は公式/主要企業/主要メディアに限定）
- 有料記事・会員限定・配布資料は要約中心に倒し、抜粋は最小限（必要なら取得自体を禁止）

### 4.5 MCP接続（開発用の最小プロトコル）
- 開発用として、NDJSONの簡易stdioプロトコルを実装（[src/main.py](../../src/main.py)）
  - `{"action": "list_tools"}` → ツール名のリストを返す
  - `{"action": "invoke", "tool": "fetch_url", "params": {...}}` のように呼び出す
- 実運用で必要なら、正式なMCPフレームワーク実装に置き換える

---

## 5. 評価（“良い要約”を定義して自動で崩れないようにする）
### 5.1 ゴールデンセットを作る
- 10〜30本のURL（公式/企業/メディア）
- それを人手で「期待するトレンドTop5」を作成

### 5.2 自動チェック観点
- URLが付いているか（必須）
- 結論/見解に「根拠の現文（短い抜粋）」が付いているか（必須）
- 抜粋が最大500文字以内か（必須）
- 抜粋に位置情報が付いているか（見出し名/段落/タイムスタンプ等）。取れない場合は「不明」と明示されているか（必須）
- 同じ話題の重複が多すぎないか
- “新規性”が言語化されているか（昨年比/従来比）
- 数字/固有名詞の出典があるか

---

## 8. 根拠の現文（抜粋）の取り扱い
- 抜粋は必要最小限（1〜3文程度）に留め、必ずURLと位置情報（見出し名/段落/タイムスタンプ）を添える
- 有料記事や配布資料は全文再掲を避け、要約中心で扱う

---

## 6. 運用設計（イベント期間中の回し方）
- 毎日同じ時刻に「日次ブリーフ」を生成
- 週次で「テーマ別統合レポート」を生成
- 重要な誤りが出たら「訂正ログ」を残す（追記方式）

---

## 7. 次のアクション（このリポジトリでやるなら）
- まずは `reports/` と `sources/` のディレクトリ設計を決める
- 次に、ツール連携（MCP等）で最小ツール4つを実装
- 最後に、CES 2026 を題材にゴールデンセットで評価

---

## 9. テスト（MVP）
- 仕様: [test_spec.md](./test_spec.md)
- 依存: `env/requirements.txt` + `env/requirements-dev.txt`
- 実行（ローカル例）:
  - `python -m pytest -q`
- 実行（Docker例）:
  - `docker build -t market-analysis-test -f env/Dockerfile.test .`
  - `docker run --rm market-analysis-test`
- CI（GitHub Actions）:
  - ワークフロー: `.github/workflows/ci.yml`
  - Python 3.12 / pip cache / `python -m pytest -q`
- 方針: 外部ネットワークに依存しない（HTTP取得はmockする）

必要なら、こちらで「MCPサーバーの最小実装（Python/Node）」まで一気に雛形を作れます。希望言語（PythonかNode）と、取得したいデータソースの優先順位（公式/企業/メディア/動画）を教えてください。
